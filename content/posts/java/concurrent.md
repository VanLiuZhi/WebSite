---
weight: 1
title: "Java 并发"
date: 2020-08-16T14:00:00+08:00
lastmod: 2020-08-16T14:00:00+08:00
draft: false
author: "VanLiuZhi"
authorLink: "https://www.liuzhidream.com"
description: "Java 并发"
resources:
- name: "base-image"
  src: "base-image.jpg"

tags: [Java, Note]
categories: [Java]

lightgallery: true

toc:
  auto: false
---

review

<!-- more -->

## 基础与名词解释

竞态条件: 多个线程竞争同一个资源，如果对资源的访问顺序敏感，就称存在竞态条件
临界区: 导致竞态条件发生的代码称为临界区

Java运行至少启动两个线程，一个是main线程，一个是垃圾回收线程(当然实际肯定不止，还有其它线程协调其它工作);Java启动的每一个进程都有一个独立的JVM

JMM通过控制主内存与每个线程的本地内存之间的交互，来为java程序员提供内存可见性保证(也就是线程A要向线程B发送消息，线程A要把数据先写到主内存，由线程B去主内存读取数据)

Java内存模型没有具体讲述前面讨论的执行策略是由编译器，CPU，缓存控制器还是其它机制促成的。甚至没有用开发人员所熟悉的类，对象及方法来讨论。取而代之，Java内存模型中仅仅定义了线程和内存之间那种抽象的关系。众所周知，每个线程都拥有自己的工作存储单元（缓存和寄存器的抽象）来存储线程当前使用的变量的值。Java内存模型仅仅保证了代码指令与变量操作的有序性，大多数规则都只是指出什么时候变量值应该在内存和线程工作内存之间传输。这些规则主要是为了解决如下三个相互牵连的问题：

1. 原子性：哪些指令必须是不可分割的。在Java内存模型中，这些规则需声明仅适用于-—实例变量和静态变量，也包括数组元素，但不包括方法中的局部变量-—的内存单元的简单读写操作。
2. 可见性：在哪些情况下，一个线程执行的结果对另一个线程是可见的。这里需要关心的结果有，写入的字段以及读取这个字段所看到的值。
3. 有序性：在什么情况下，某个线程的操作结果对其它线程来看是无序的。最主要的乱序执行问题主要表现在读写操作和赋值语句的相互执行顺序上。

访问临界区，需要获取到锁，操作完，释放锁。而对于锁本身，也是一种临界资源，是不允许多个线程共同持有的，同一时刻，只能够一个线程持有

Java中有另外一个概念，叫做监视器，《深入Java虚拟机》中如下描述监视器：

可以将监视器比作一个建筑，它有一个很特别的房间，房间里有一些数据，而且在同一时间只能被一个线程占据。
一个线程从进入这个房间到它离开前，它可以独占地访问房间中的全部数据。如果用一些术语来定义这一系列动作：

进入这个建筑叫做“进入监视器”
进入建筑中的那个特别的房间叫作“获得监视器”
占据房间叫做“持有监视器”
离开房间叫做“释放监视器”
离开建筑叫做“退出监视器”

（对于开发者来说，你使用一个synchronized关键字就有了监视器的效果，监视器依赖JVM，而JVM依赖操作系统，操作系统则会进一步依赖软件甚至硬件，就是这样层层封装）
其实废话这么多，一个同步方法内（同步代码块）中所有的内容，就是属于同一个监视区域

现代处理器，单CPU多核，共享三级缓存，每个核心有2个二级缓存，上面是一级缓存。数据必须通过缓存加载到寄存器，CPU不会直接从内存加载数据

要理解JMM是一种抽象的概念，不是真实存在的，是一组规则，通过这组规则控制程序中各个变量在共享数据域和私有数据域的访问方式，什么规则呢？
就是围绕原子性，可见性，有序性展开的

操作系统进程创建调用fork，线程的创建调用pthread_create 都是c++提供的，主要是说Linux

编译优化: JIT除了具有缓存的功能外，还会对代码做各种优化。比如 逃逸分析、 锁消除、 锁膨胀、 方法内联、 空值检查消除、 类型检测消除、公共子表达式消除

JTI即时编译，通过热点探测机制把解释器翻译执行的热点代码编译成机器码，缓存起来，方便下次调用，通过对栈顶计数，对程序计数(超过阈值认为它是热点代码)，然后触发JIT，在HotSpot虚拟机中使用的是第二种——基于计数器的热点探测方法，因此它为每个方法准备了两个计数器:方法调用计数器和回边计数器

## 并发编程模型的分类

`在并发编程中，我们需要处理两个关键问题：`

线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体），通信是指线程之间以何种机制来交换信息。

`在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递`

在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。
在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。

`同步是指程序用于控制不同线程之间操作发生相对顺序的机制`

在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。
在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。

## 知识点概况

1. 竞态条件和临界资源

2. JMM -- Java Memony Model 是一种抽象，一组规则，围绕着3个特性展开，如何做到这三点就是我们需要理解的

    1. 原子性
    2. 有序性
    3. 可见性

3. 监视器 Monitor

4. JTI 即时编译，通过热点探测（对程序计数统计）

5. 并发编程模型

    线程如何`通信`和`同步`

6. 上下文: 某一时间点，CPU寄存器和计数器的内容(还有栈信息等)，线程只需要保存这些内容做切换

7. CLH锁即Craig, Landin, and Hagersten (CLH) locks。CLH锁是一个自旋锁。能确保无饥饿性。提供先来先服务的公平性

线程的上下文信息是保存在内存中的，切换回来的时候去内存中找到然后恢复到寄存器中

## 创建线程的方式

1. 实现Runable接口
2. 继承Thread类
3. 实现Callable接口

1，2都是类似的，3是用线程池

7. 被阻塞的线程不会消耗CPU，但是线程状态的转换需要相对比较长的时间

8. park unpark 挂起，恢复

## start 和 run 方法的区别

start方法会创建线程，进入就绪状态，分配到时间的时候片执行run方法
直接用run方法不会有多线程，就和普通的方法一样

## 线程状态

1. wait(),join(),LockSupport.lock()方法线程会进入到WAITING

2. wait(long timeout)，sleep(long),join(long),LockSupport.parkNanos(),LockSupport.parkUtil()增加了超时等待的功能，也就是调用这些方法后线程会进入TIMED_WAITING

3. 当超时等待时间到达后，线程会切换到Runable的状态，另外当WAITING和TIMED_WAITING状态时可以通过Object.notify(),Object.notifyAll()方法使线程转换到Runable状态

4. 当线程出现资源竞争时，即等待获取锁的时候，线程会进入到BLOCKED阻塞状态

5. 当线程获取锁时，线程进入到Runable状态

6. 线程运行结束后，线程进入到TERMINATED状态

7. 当线程进入到synchronized方法或者synchronized代码块时，线程切换到的是BLOCKED状态，而使用java.util.concurrent.locks下lock进行加锁的时候线程切换的是WAITING或者TIMED_WAITING状态，因为lock会调用LockSupport的方法。

## 线程基本操作

1. interrupted 中断

主要关注标志位的状态，标志位用来做判断，
interrupted interrupt isInterrupted

2. join

3. sleep

sleep线程不会失去锁

sleep()方法是Thread的静态方法，而wait是Object实例方法

wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。
而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁；

sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行

4. yield

调用后当前线程让出时间片，拥有同级别优先级的线程可以去竞争该时间片，让出时间片后，加入到下一次的cpu资源竞争中

## 获取线程的状态

```java
System.out.println("线程唯一标识符：" + thread.getId());
System.out.println("线程名称：" + thread.getName());
System.out.println("线程状态：" + thread.getState());
System.out.println("线程优先级：" + thread.getPriority());
```

## notify notifyAll 

## Daemon 守护线程

一个进程包含主线程，2个子线程，1个守护线程

主线程任务完成了，子线程任务也完成了，这个时候守护线程会自己结束，不管任务有没有完成

## 什么是线程安全？

当多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那这个对象是线程安全的。

## 线程通信，消费者和生产者编程实践

## Java中共享变量是哪些？

方法中的局部变量不是共享的，实例域，静态域和数组元素都是在堆内存中的，是共享的

## Java内存模型

## 重排序

分类

1. 编译器优化的重排序

编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序

2. 指令级并行的重排序

现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序

3. 内存系统的重排序

由于处理器使用缓存，读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行的，详细说明下这种情况

举例: 

- 什么是缓冲区

发生这种情况是由于处理器使用了缓冲区，比如对变量的写入先写到缓冲区，然后再刷新到主存(现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟)

- 场景

理解这个概念后，有一段代码执行顺序是这样的，A，B线程，先写a=1，b=2到主存，然后读取主存共享变量 a=b=0

- 执行情况

内存的操作情况是 写，然后读(`写->读`) 然而有缓冲区，可能是写到缓冲区后，读主存，然后缓冲区刷新到主存(`读->写`)

- 结论

由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。可以用

常见的处理器都允许Store-Load重排序；
常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO和x86拥有相对较强的处理器内存模型，它们`仅允许对写-读操作做重排序`（因为它们都使用了写缓冲区）

- 通过内存屏障解决重排序问题

Java编译器通过插入内存屏障来解决重排序，内存屏障是指令，依托于处理器的实现，使用内存屏障有一定的性能损坏，因为原来通过缓冲区加快了处理器指令流水的运行，使用内存屏障就是要先把缓冲区数据刷新到主存后，才执行后面的指令

- 内存屏障指令举例 

`LoadLoad Barriers`    

Load1; LoadLoad; Load2   确保Load1数据的装载，之前于Load2及所有后续装载指令的装载

`StoreLoad Barriers`   

Store1; StoreStore; Store2  确保Store1数据对其他处理器可见（刷新到内存），之前于Store2及所有后续存储指令的存储

`LoadStore Barriers`   

Load1; LoadStore; Store2   确保Load1数据装载，之前于Store2及所有后续的存储指令刷新到内存

`StoreLoad Barriers`   

Store1; StoreLoad; Load2   确保Store1数据对其他处理器变得可见（指刷新到内存），之前于Load2及所有后续装载指令的装。StoreLoad Barriers会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令

- 内存屏障总结

StoreLoad Barriers 是现代处理器都会支持的(其它的不一定)。总的来说内存屏障指令之前的指令，会先执行，有写操作的都要刷新主存后，后面的指令才执行，这样后面的指令就能读到前一个指令写入的数据(从主存读)，实现了数据的可见性

`重排序`

对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序(不是所有的编译器重排序都要禁止)。对于处理器重排序，JMM的处理器重排序规则会要求java编译器在生成指令序列时，插入特定类型的内存屏障(memory barriers，intel称之为memory fence)指令，通过内存屏障指令来禁止特定类型的处理器重排序(不是所有的处理器重排序都要禁止)

JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证

总结: 重排序是对Java源代码编译后的字节码做排序，现代处理都能并行处理，也就是一次执行多条指令，而旧体系的处理器或者单片机是按照时钟周期一条一条指令执行的。编译器编译源代码，处理器去执行语句都可能发生重排序


## 什么时候不能重排序？

发生数据依赖的时候，不能重排序

如果两个操作访问同一个变量，且这两个操作有一个为写操作，此时这两个操作就存在数据依赖性，体现在`有写操作`上

读后写，写后读，写后写 都是数据依赖  读后读  没关系，都是读取

## as-if-serial

遵守as-if-serial语义的编译器，runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的

## happens-before

通过happens-before来描述内存可见性，或者说是`用来描述可见性的一种规则`

## 缓存一致性

指的是使用了缓存和数据库的情况下，如何保证数据一致性，我们会把高频读的数据放到缓存，但是修改数据库的时候需要把缓存删除，再建立新的

## JMM

Java线程之间的通信由Java内存模型（简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。

从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。

## JMM相关操作

lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态
unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中
use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎
assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量
store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作
write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中

这个只需要知道个大概就行了:

从主存复制到工作内存 -> 就需要按顺序地执行read和load操作
从工作内存复制到主存 -> 就需要按顺序地执行store和write操作

## Java内存模型同步规则

不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中

一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作

一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现

如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值

如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。
对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）

## volatile

volatile缓存可见性实现原理

JMM内存交互层面：volatile修饰的变量的read、load、use操作和assign、store、write必须是连续的，即修改后必须立即同步会主内存，使用时必须从主内存刷新，由此保证volatile变量的可见性。
底层实现：通过汇编lock前缀指令，它会锁定变量缓存行区域并写回主内存，这个操作称为“缓存锁定”，缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据。一个处理器的缓存回写到内存内存会导致其他处理器的缓存无效

汇编代码查看 -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp (可以借助idea工具，把参数加到执行后面，观察汇编指令)

## 创建线程

- 实现Runnable接口
- 继承Thread类

```java
package concurrent;

public class MyThread implements Runnable {
    @Override
    public void run() {
        System.out.println("run method");
    }

    public static void main(String[] args) {
        Thread thread = new Thread(new MyThread());
        thread.start();
        System.out.println("线程唯一标识符：" + thread.getId());
        System.out.println("线程名称：" + thread.getName());
        System.out.println("线程状态：" + thread.getState());
        System.out.println("线程优先级：" + thread.getPriority());
    }
}

class MyThread2 extends Thread {

    @Override
    public void run() {
        System.out.println("run myThread2");
    }

    public static void main(String[] args) {
        MyThread2 myThread2 = new MyThread2();
        myThread2.start();
    }
}
```

## 线程优先级

从1到10，1最低，10最高

## 线程状态

new 新建
runnable 可运行
blocked 阻塞
waiting 等待
time waiting 定时等待
terminated 终止

状态转换流程

1. 线程创建，进入new状态
2. 调用 start 方法，进入 runnable 状态
3. JVM 按照线程优先级及时间分片等执行 runnable 状态的线程。开始执行时，进入 running 状态
4. 如果线程执行 sleep、wait、join，或者进入 IO 阻塞等。进入 wait 或者 blocked 状态
5. 线程执行完毕后，线程被线程队列移除。最后为 terminated 状态

## 缓存一致性协议

CPU多个核是共享内存的，当2个核都要去操作变量i的时候，如何保证数据一致性？

方式:

1. 总线加锁(非常耗损性能)
2. 缓存一致性协议

现代处理器通过操作系统和处理器架构，配合特定的指令集实现缓存一致性

比较常见的协议: MESI

M 修改 Modified
E 独占 Exclusive
S 共享 Shared
I 无效 Invalid

流程举例:

1. 主存有变量i，CPU1读取变量i，变量变成E(独占)
2. CPU2读取变量i，通过广播和`总线嗅探机制`，此时变量i在CPU1和CPU2中都变成S(共享)
3. CPU1修改了变量i，在CPU1中，i变成M(修改)，通过总线嗅探，CPU2中i变成I(无效)
4. 如果CPU2需要用到i，就需要从主存重新读取，此时就等待CPU1的i回写到主存。注意CPU1修改了i之后，由于CPU2的i I(无效)，此时CPU1的i是E(独占)，并且这个修改不会直接写到主存，需要在某个特定的时间点才会写入
5. i写入后，CPU2读取到，此时CPU1和CPU2的i又变成S(共享)


### 锁缓存行

通过LOCK指令来实现的缓存一致性协议，有一个缓存行的概念 cache line 64byte

什么情况下不能用缓存一致性协议

1. 不支持(现代处理器都支持)
2. 跨缓存行，就是超过了cache line的大小，此时就会用锁总线

`/sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size` 感兴趣可以看看这里的东西，这个文件记录了cache line大小，为64

### 缓存淘汰策略

LRU 最近最少使用的，会被淘汰掉，在CPU的cache中就是被踢出了

## synchronized

用法分类，可以分为实例和类

给一个对象上锁，如果对象是静态的，那么就是和类有关的，就是类锁，方法也是同样的道理，也就是说首先要区分是类锁还是实例锁
使用了对象锁，如果临界区代码没有和被锁住的对象有交集，那么锁消除不会出现竞争

实例锁: 同一个实例访问有竞争，不同实例访问没有
类锁: 会拦截所有线程的访问






